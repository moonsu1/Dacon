{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f76990a-c7de-4679-9077-447e0a51487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\moons\\\\데이콘'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f6df82-1bd5-4812-b8c3-343a0ddd047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d25b928-725e-4da7-8b6b-815355c18282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# from keras import models, layers\n",
    "# from keras import Input\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers, initializers, regularizers, metrics\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, Input, ZeroPadding2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b0530-bf4c-4bb5-ad7a-b3adcbd7cbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c86892b4-33f5-4eb0-b300-7c83e334dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/ 255.0,  #값을 0과 1사이로 정규화 -> 데이터가 처음에 들어올 때 이미지는 0~255의 사이의 값으로 들어옴\n",
    "    rotation_range=30, #무작위 회전각도 30도 이내\n",
    "    width_shift_range=30, \n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1, #층 밀리기 강도 20%   ???\n",
    "    zoom_range=0.3, #무작위 줌 범위 20%  -> 질문 데이터 사이즈 지정하면 원래 크기인 32by32를 크기 조정하는 것이라고 했는데\n",
    "    # zoom_range를 이용해서도 크기조정을 하니 데이터 사이즈 지정은 오히려 자유롭게 해도 되는 것인가?\n",
    "    horizontal_flip=True, #무작위로 가로로 뒤집음\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2) # set validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e0c4a-e785-446c-94bd-1e125f3b06ec",
   "metadata": {},
   "source": [
    "# 이미지 가로 세로 size 지정, 배치사이즈 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c665d3c-4786-40c8-abee-76d39948f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/2차/samul_data/train'\n",
    "img_height = 50\n",
    "img_width = 50\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b6c07-a1f3-4e2b-88bc-c8f4d062f623",
   "metadata": {},
   "source": [
    "# train data 를 디렉토리에서 받아옴\n",
    "## train 폴더 안에 있는 디렉토리 이름이 class로 자동으로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21d40059-c707-447c-82b4-84a7bf91ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd82d031-5c22-4216-88be-b027a4b6b924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bc9b8de-3073-4946-8ad1-9cb6e50e0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_generator.next()\n",
    "#next 할 떄마다 한 batch 씩 들어간다고 보면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6701042e-f20c-4f15-9864-df32c94261c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 50, 50, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "#256의 batch size, 에 100,100의 이미지 사이즈,   3 -> RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca5d0106-825a-48aa-91b3-20acbe54f3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] \n",
    "#NEXT로 한 batch 만 큼 들어갔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a277b69-1254-4dfc-a6c8-c68563af7b8c",
   "metadata": {},
   "source": [
    "# 데이터가 제대로 들어갔는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9214d6b-46b2-437a-849c-b13a07eda496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train[200].shape)\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9d668-8317-41ab-ae5f-973c8162170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch normalization -> 각 레이어마다 input 값들의 분포가 달라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a80e9-e4e1-42bd-beaf-2088c2e4a975",
   "metadata": {},
   "source": [
    "# resnet 손코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39f70c1f-ef9b-4d18-af66-d05d3ddf125d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 50, 50, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 56, 56, 3)    0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 25, 25, 64)   9472        zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 25, 25, 64)   256         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 25, 25, 64)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 27, 27, 64)   0           activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 13, 13, 64)   0           zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 13, 13, 64)   4160        max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 13, 13, 64)   256         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 13, 13, 64)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 13, 13, 64)   36928       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 13, 13, 64)   256         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 13, 13, 64)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 13, 13, 256)  16640       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 13, 13, 256)  16640       max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 13, 13, 256)  1024        conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 13, 13, 256)  1024        conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 13, 13, 256)  0           batch_normalization_274[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 13, 13, 256)  0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 13, 13, 64)   16448       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 13, 13, 64)   256         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 13, 13, 64)   0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 13, 13, 64)   36928       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 13, 13, 64)   256         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 13, 13, 64)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 13, 13, 256)  16640       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 13, 13, 256)  1024        conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 13, 13, 256)  0           batch_normalization_278[0][0]    \n",
      "                                                                 activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 13, 13, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 13, 13, 64)   16448       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 13, 13, 64)   256         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 13, 13, 64)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 13, 13, 64)   36928       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 13, 13, 64)   256         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 13, 13, 64)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 13, 13, 256)  16640       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 13, 13, 256)  1024        conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 13, 13, 256)  0           batch_normalization_281[0][0]    \n",
      "                                                                 activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 13, 13, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 7, 7, 128)    32896       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 7, 7, 128)    512         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 128)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 7, 7, 128)    147584      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 7, 7, 128)    512         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 7, 7, 128)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 7, 7, 512)    66048       activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 7, 7, 512)    131584      activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 7, 7, 512)    2048        conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 7, 7, 512)    2048        conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 7, 7, 512)    0           batch_normalization_284[0][0]    \n",
      "                                                                 batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 512)    0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 7, 7, 128)    65664       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 7, 7, 128)    512         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 128)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 7, 7, 128)    147584      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 7, 7, 128)    512         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 128)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 7, 7, 512)    66048       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 7, 7, 512)    2048        conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 7, 7, 512)    0           batch_normalization_288[0][0]    \n",
      "                                                                 activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 7, 7, 512)    0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 7, 7, 128)    65664       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 7, 7, 128)    512         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 7, 7, 128)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 7, 7, 128)    147584      activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 7, 7, 128)    512         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 7, 7, 128)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 7, 7, 512)    66048       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 7, 7, 512)    2048        conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 7, 7, 512)    0           batch_normalization_291[0][0]    \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 7, 7, 512)    0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 7, 7, 128)    65664       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 7, 7, 128)    512         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 7, 7, 128)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 7, 7, 128)    147584      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 7, 7, 128)    512         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 7, 7, 128)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 7, 7, 512)    66048       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 7, 7, 512)    2048        conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 7, 7, 512)    0           batch_normalization_294[0][0]    \n",
      "                                                                 activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 7, 7, 512)    0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 4, 4, 256)    131328      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 4, 4, 256)    1024        conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 4, 4, 256)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 4, 4, 256)    590080      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 4, 4, 256)    1024        conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 4, 4, 256)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 4, 4, 1024)   263168      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 4, 4, 1024)   525312      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 4, 4, 1024)   4096        conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 4, 4, 1024)   4096        conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_297[0][0]    \n",
      "                                                                 batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 4, 4, 1024)   0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 4, 4, 256)    262400      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 4, 4, 256)    1024        conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 4, 4, 256)    0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 4, 4, 256)    590080      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 4, 4, 256)    1024        conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 4, 4, 256)    0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 4, 4, 1024)   263168      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 4, 4, 1024)   4096        conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_301[0][0]    \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 4, 4, 1024)   0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 4, 4, 256)    262400      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 4, 4, 256)    1024        conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 4, 4, 256)    0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 4, 4, 256)    590080      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 4, 4, 256)    1024        conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 4, 4, 256)    0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 4, 4, 1024)   263168      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 4, 4, 1024)   4096        conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_304[0][0]    \n",
      "                                                                 activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 4, 4, 1024)   0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 4, 4, 256)    262400      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 4, 4, 256)    1024        conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 4, 4, 256)    0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 4, 4, 256)    590080      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 4, 4, 256)    1024        conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 4, 4, 256)    0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 4, 4, 1024)   263168      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 4, 4, 1024)   4096        conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_307[0][0]    \n",
      "                                                                 activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 4, 4, 1024)   0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 4, 4, 256)    262400      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 4, 4, 256)    1024        conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 4, 4, 256)    0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 4, 4, 256)    590080      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 4, 4, 256)    1024        conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 4, 4, 256)    0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 4, 4, 1024)   263168      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 4, 4, 1024)   4096        conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_310[0][0]    \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 4, 4, 1024)   0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 4, 4, 256)    262400      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 4, 4, 256)    1024        conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 4, 4, 256)    0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 4, 4, 256)    590080      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 4, 4, 256)    1024        conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 4, 4, 256)    0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 4, 4, 1024)   263168      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 4, 4, 1024)   4096        conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_313[0][0]    \n",
      "                                                                 activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 4, 4, 1024)   0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 2, 2, 512)    524800      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 2, 2, 512)    2048        conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 2, 2, 512)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 2, 2, 512)    2359808     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 2, 2, 512)    2048        conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 2, 2, 512)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 2, 2, 2048)   2099200     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 2, 2, 2048)   8192        conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 2, 2, 2048)   8192        conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_316[0][0]    \n",
      "                                                                 batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 2, 2, 2048)   0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 2, 2, 512)    1049088     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 2, 2, 512)    2048        conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 2, 2, 512)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 2, 2, 512)    2359808     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 2, 2, 512)    2048        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 2, 2, 512)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 2, 2, 2048)   8192        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_320[0][0]    \n",
      "                                                                 activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 2, 2, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 2, 2, 512)    1049088     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 2, 2, 512)    2048        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 2, 2, 512)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 2, 2, 512)    2359808     activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 2, 2, 512)    2048        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 2, 2, 512)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 2, 2, 2048)   8192        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_323[0][0]    \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 2, 2, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 10)           20490       global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(50, 50, 3),dtype = 'float', name='input')\n",
    " \n",
    " \n",
    "def conv1_layer(x):    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    " \n",
    "    return x   \n",
    " \n",
    "    \n",
    " \n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)     \n",
    " \n",
    "    shortcut = x\n",
    " \n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            shortcut = x        \n",
    "    \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    " \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv5_layer(x):\n",
    "    shortcut = x    \n",
    "  \n",
    "    for i in range(3):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])  \n",
    "            x = Activation('relu')(x)      \n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)           \n",
    "            \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)       \n",
    " \n",
    "            shortcut = x                  \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    " \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(10, activation='softmax')(x)\n",
    " \n",
    "resnet50 = Model(input_tensor, output_tensor)\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14dbc669-f11d-4869-b4f5-6393494d10e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 50, 50, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 56, 56, 3)    0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 25, 25, 64)   9472        zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 25, 25, 64)   256         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 25, 25, 64)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 27, 27, 64)   0           activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 13, 13, 64)   0           zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 13, 13, 64)   4160        max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 13, 13, 64)   256         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 13, 13, 64)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 13, 13, 64)   36928       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 13, 13, 64)   256         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 13, 13, 64)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 13, 13, 256)  16640       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 13, 13, 256)  16640       max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 13, 13, 256)  1024        conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 13, 13, 256)  1024        conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 13, 13, 256)  0           batch_normalization_274[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 13, 13, 256)  0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 13, 13, 64)   16448       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 13, 13, 64)   256         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 13, 13, 64)   0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 13, 13, 64)   36928       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 13, 13, 64)   256         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 13, 13, 64)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 13, 13, 256)  16640       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 13, 13, 256)  1024        conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 13, 13, 256)  0           batch_normalization_278[0][0]    \n",
      "                                                                 activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 13, 13, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 13, 13, 64)   16448       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 13, 13, 64)   256         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 13, 13, 64)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 13, 13, 64)   36928       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 13, 13, 64)   256         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 13, 13, 64)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 13, 13, 256)  16640       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 13, 13, 256)  1024        conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 13, 13, 256)  0           batch_normalization_281[0][0]    \n",
      "                                                                 activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 13, 13, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 7, 7, 128)    32896       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 7, 7, 128)    512         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 128)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 7, 7, 128)    147584      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 7, 7, 128)    512         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 7, 7, 128)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 7, 7, 512)    66048       activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 7, 7, 512)    131584      activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 7, 7, 512)    2048        conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 7, 7, 512)    2048        conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 7, 7, 512)    0           batch_normalization_284[0][0]    \n",
      "                                                                 batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 512)    0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 7, 7, 128)    65664       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 7, 7, 128)    512         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 128)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 7, 7, 128)    147584      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 7, 7, 128)    512         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 128)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 7, 7, 512)    66048       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 7, 7, 512)    2048        conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 7, 7, 512)    0           batch_normalization_288[0][0]    \n",
      "                                                                 activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 7, 7, 512)    0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 7, 7, 128)    65664       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 7, 7, 128)    512         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 7, 7, 128)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 7, 7, 128)    147584      activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 7, 7, 128)    512         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 7, 7, 128)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 7, 7, 512)    66048       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 7, 7, 512)    2048        conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 7, 7, 512)    0           batch_normalization_291[0][0]    \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 7, 7, 512)    0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 7, 7, 128)    65664       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 7, 7, 128)    512         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 7, 7, 128)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 7, 7, 128)    147584      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 7, 7, 128)    512         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 7, 7, 128)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 7, 7, 512)    66048       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 7, 7, 512)    2048        conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 7, 7, 512)    0           batch_normalization_294[0][0]    \n",
      "                                                                 activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 7, 7, 512)    0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 4, 4, 256)    131328      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 4, 4, 256)    1024        conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 4, 4, 256)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 4, 4, 256)    590080      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 4, 4, 256)    1024        conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 4, 4, 256)    0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 4, 4, 1024)   263168      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 4, 4, 1024)   525312      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 4, 4, 1024)   4096        conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 4, 4, 1024)   4096        conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_297[0][0]    \n",
      "                                                                 batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 4, 4, 1024)   0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 4, 4, 256)    262400      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 4, 4, 256)    1024        conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 4, 4, 256)    0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 4, 4, 256)    590080      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 4, 4, 256)    1024        conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 4, 4, 256)    0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 4, 4, 1024)   263168      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 4, 4, 1024)   4096        conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_301[0][0]    \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 4, 4, 1024)   0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 4, 4, 256)    262400      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 4, 4, 256)    1024        conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 4, 4, 256)    0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 4, 4, 256)    590080      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 4, 4, 256)    1024        conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 4, 4, 256)    0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 4, 4, 1024)   263168      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 4, 4, 1024)   4096        conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_304[0][0]    \n",
      "                                                                 activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 4, 4, 1024)   0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 4, 4, 256)    262400      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 4, 4, 256)    1024        conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 4, 4, 256)    0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 4, 4, 256)    590080      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 4, 4, 256)    1024        conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 4, 4, 256)    0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 4, 4, 1024)   263168      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 4, 4, 1024)   4096        conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_307[0][0]    \n",
      "                                                                 activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 4, 4, 1024)   0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 4, 4, 256)    262400      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 4, 4, 256)    1024        conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 4, 4, 256)    0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 4, 4, 256)    590080      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 4, 4, 256)    1024        conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 4, 4, 256)    0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 4, 4, 1024)   263168      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 4, 4, 1024)   4096        conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_310[0][0]    \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 4, 4, 1024)   0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 4, 4, 256)    262400      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 4, 4, 256)    1024        conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 4, 4, 256)    0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 4, 4, 256)    590080      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 4, 4, 256)    1024        conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 4, 4, 256)    0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 4, 4, 1024)   263168      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 4, 4, 1024)   4096        conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_313[0][0]    \n",
      "                                                                 activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 4, 4, 1024)   0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 2, 2, 512)    524800      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 2, 2, 512)    2048        conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 2, 2, 512)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 2, 2, 512)    2359808     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 2, 2, 512)    2048        conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 2, 2, 512)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 2, 2, 2048)   2099200     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 2, 2, 2048)   8192        conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 2, 2, 2048)   8192        conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_316[0][0]    \n",
      "                                                                 batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 2, 2, 2048)   0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 2, 2, 512)    1049088     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 2, 2, 512)    2048        conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 2, 2, 512)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 2, 2, 512)    2359808     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 2, 2, 512)    2048        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 2, 2, 512)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 2, 2, 2048)   8192        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_320[0][0]    \n",
      "                                                                 activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 2, 2, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 2, 2, 512)    1049088     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 2, 2, 512)    2048        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 2, 2, 512)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 2, 2, 512)    2359808     activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 2, 2, 512)    2048        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 2, 2, 512)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 2, 2, 2048)   8192        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_323[0][0]    \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 2, 2, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 10)           20490       global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337a735-fb66-46e3-865d-348ad11323da",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9823041-e05e-4f84-a3b9-56eb17604b22",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 48, 48, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 155,338\n",
      "Trainable params: 155,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# with tf.device('/GPU:0'):\n",
    "#     model = Sequential([\n",
    "#         Conv2D(16, (3, 3), activation='relu', input_shape=(50, 50, 3)),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Conv2D(32, (3, 3), activation='relu',padding='same'),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Conv2D(64, (3, 3), activation='relu',padding='same'),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Conv2D(64, (3, 3), activation='relu',padding='same'),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Conv2D(128, (3, 3), activation='relu',padding='same'),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Flatten(),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(128, activation='relu'),\n",
    "#         Dense(32, activation='relu'),\n",
    "#         Dense(10, activation='softmax')\n",
    "#     ])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893a34a-1176-4410-9058-f093fdb70ffe",
   "metadata": {},
   "source": [
    "# 임시로 만들어놓았던 간단한 cnn 코드로 fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99830739-6e4d-4ab3-a52a-83c201bd2598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 2.0985 - acc: 0.2034 - val_loss: 1.9176 - val_acc: 0.2806\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.91764, saving model to check_samul.ckpt\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 1.8795 - acc: 0.3009 - val_loss: 1.7691 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.91764 to 1.76914, saving model to check_samul.ckpt\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 49s 311ms/step - loss: 1.7551 - acc: 0.3544 - val_loss: 1.6454 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.76914 to 1.64537, saving model to check_samul.ckpt\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 46s 294ms/step - loss: 1.6831 - acc: 0.3870 - val_loss: 1.6171 - val_acc: 0.4046\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.64537 to 1.61706, saving model to check_samul.ckpt\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 1.6145 - acc: 0.4133 - val_loss: 1.5423 - val_acc: 0.4406\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.61706 to 1.54234, saving model to check_samul.ckpt\n",
      "40/40 [==============================] - 10s 236ms/step - loss: 1.5404 - acc: 0.4466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5403934717178345, 0.4465999901294708]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"check_samul.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1)\n",
    "\n",
    "model.fit(train_generator, \n",
    "          validation_data=(validation_generator),\n",
    "          epochs=5,\n",
    "          callbacks=[checkpoint],\n",
    "          )\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8082e-4d2a-4e49-985f-6a2c2e73a6c9",
   "metadata": {},
   "source": [
    "# resnet 으로 fitting 하여 cnn 간단한 코드와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9967792e-4123-4d16-8592-e52da0b85cd3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 1.1714 - acc: 0.5908 - val_loss: 1.4870 - val_acc: 0.4963\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49630, saving model to check_samul_resnet.ckpt\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 48s 306ms/step - loss: 1.1269 - acc: 0.6039 - val_loss: 1.5865 - val_acc: 0.4669\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49630\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 49s 308ms/step - loss: 1.1005 - acc: 0.6119 - val_loss: 1.5759 - val_acc: 0.4989\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.49630 to 0.49890, saving model to check_samul_resnet.ckpt\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 1.0824 - acc: 0.6196 - val_loss: 1.7018 - val_acc: 0.4881\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.49890\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 1.0912 - acc: 0.6238 - val_loss: 1.9393 - val_acc: 0.3648\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49890\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 46s 294ms/step - loss: 1.1321 - acc: 0.6038 - val_loss: 2.2413 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.49890\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 1.1684 - acc: 0.5895 - val_loss: 1.3666 - val_acc: 0.5315\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.49890 to 0.53150, saving model to check_samul_resnet.ckpt\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 48s 304ms/step - loss: 1.0541 - acc: 0.6347 - val_loss: 1.7810 - val_acc: 0.4824\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53150\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 0.9935 - acc: 0.6502 - val_loss: 1.9482 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53150\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 46s 294ms/step - loss: 1.2631 - acc: 0.5695 - val_loss: 1.9541 - val_acc: 0.4087\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53150\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 1.2372 - acc: 0.5752 - val_loss: 2.8924 - val_acc: 0.3178\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53150\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 1.1137 - acc: 0.6109 - val_loss: 3.5745 - val_acc: 0.3585\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.53150\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 1.2832 - acc: 0.5646 - val_loss: 1.9225 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53150\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 50s 319ms/step - loss: 1.2336 - acc: 0.5821 - val_loss: 1.4584 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.53150\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 50s 317ms/step - loss: 1.0790 - acc: 0.6277 - val_loss: 1.2063 - val_acc: 0.5738\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.53150 to 0.57380, saving model to check_samul_resnet.ckpt\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.9648 - acc: 0.6614 - val_loss: 1.1042 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.57380 to 0.61470, saving model to check_samul_resnet.ckpt\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 1.1041 - acc: 0.6190 - val_loss: 1.4397 - val_acc: 0.5241\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.61470\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 1.0931 - acc: 0.6214 - val_loss: 1.2614 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.61470\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 48s 304ms/step - loss: 0.9814 - acc: 0.6584 - val_loss: 1.0562 - val_acc: 0.6249\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.61470 to 0.62490, saving model to check_samul_resnet.ckpt\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 46s 295ms/step - loss: 1.0443 - acc: 0.6422 - val_loss: 1.3668 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.62490\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 1.1436 - acc: 0.6064 - val_loss: 1.1453 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.62490\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 53s 339ms/step - loss: 0.9580 - acc: 0.6646 - val_loss: 1.1427 - val_acc: 0.6052\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.62490\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 50s 317ms/step - loss: 0.9301 - acc: 0.6736 - val_loss: 1.0914 - val_acc: 0.6247\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.62490\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 49s 314ms/step - loss: 0.8907 - acc: 0.6919 - val_loss: 1.1325 - val_acc: 0.6167\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.62490\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.8592 - acc: 0.6997 - val_loss: 1.0297 - val_acc: 0.6457\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.62490 to 0.64570, saving model to check_samul_resnet.ckpt\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 49s 308ms/step - loss: 0.8321 - acc: 0.7089 - val_loss: 0.9608 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.64570 to 0.66710, saving model to check_samul_resnet.ckpt\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.8277 - acc: 0.7109 - val_loss: 1.1237 - val_acc: 0.6273\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.66710\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.8196 - acc: 0.7112 - val_loss: 1.0039 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.66710\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.8069 - acc: 0.7175 - val_loss: 0.9563 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.66710 to 0.67500, saving model to check_samul_resnet.ckpt\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 48s 302ms/step - loss: 0.8038 - acc: 0.7156 - val_loss: 1.6012 - val_acc: 0.5537\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.67500\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.9652 - acc: 0.6680 - val_loss: 1.1146 - val_acc: 0.5990\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.67500\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.8188 - acc: 0.7120 - val_loss: 1.0269 - val_acc: 0.6508\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.67500\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 1.0074 - acc: 0.6564 - val_loss: 176.0535 - val_acc: 0.1024\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.67500\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 47s 296ms/step - loss: 1.1335 - acc: 0.6106 - val_loss: 1.3041 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.67500\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.8781 - acc: 0.6889 - val_loss: 1.0108 - val_acc: 0.6479\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.67500\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.8201 - acc: 0.7121 - val_loss: 1.0729 - val_acc: 0.6348\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.67500\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 47s 295ms/step - loss: 0.8035 - acc: 0.7166 - val_loss: 1.0171 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.67500\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.9615 - acc: 0.6622 - val_loss: 1.3421 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.67500\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 47s 296ms/step - loss: 0.8181 - acc: 0.7118 - val_loss: 0.9919 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.67500\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.7816 - acc: 0.7271 - val_loss: 1.0876 - val_acc: 0.6376\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.67500\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.8131 - acc: 0.7152 - val_loss: 0.9461 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.67500\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.7599 - acc: 0.7315 - val_loss: 1.0145 - val_acc: 0.6546\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.67500\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 46s 295ms/step - loss: 0.7388 - acc: 0.7425 - val_loss: 0.9082 - val_acc: 0.6839\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.67500 to 0.68390, saving model to check_samul_resnet.ckpt\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 47s 296ms/step - loss: 0.7262 - acc: 0.7468 - val_loss: 1.0182 - val_acc: 0.6568\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.68390\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 47s 295ms/step - loss: 0.7196 - acc: 0.7472 - val_loss: 1.0283 - val_acc: 0.6567\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.68390\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.7162 - acc: 0.7493 - val_loss: 0.8830 - val_acc: 0.6924\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.68390 to 0.69240, saving model to check_samul_resnet.ckpt\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.7099 - acc: 0.7512 - val_loss: 1.0332 - val_acc: 0.6376\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.69240\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.7003 - acc: 0.7531 - val_loss: 0.9986 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.69240\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 50s 315ms/step - loss: 0.8186 - acc: 0.7165 - val_loss: 1.2521 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.69240\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 48s 303ms/step - loss: 0.8830 - acc: 0.6901 - val_loss: 1.0305 - val_acc: 0.6459\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.69240\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 48s 304ms/step - loss: 0.8291 - acc: 0.7106 - val_loss: 1.3770 - val_acc: 0.5693\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.69240\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 48s 306ms/step - loss: 0.7447 - acc: 0.7384 - val_loss: 0.9326 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.69240\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 0.7056 - acc: 0.7501 - val_loss: 0.8890 - val_acc: 0.6948\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.69240 to 0.69480, saving model to check_samul_resnet.ckpt\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.6860 - acc: 0.7571 - val_loss: 0.9824 - val_acc: 0.6706\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.69480\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.6756 - acc: 0.7637 - val_loss: 0.8646 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.69480 to 0.70150, saving model to check_samul_resnet.ckpt\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.6720 - acc: 0.7635 - val_loss: 0.9859 - val_acc: 0.6683\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.70150\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 0.6508 - acc: 0.7699 - val_loss: 0.8936 - val_acc: 0.6944\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.70150\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.6533 - acc: 0.7686 - val_loss: 0.8956 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.70150\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 46s 292ms/step - loss: 0.6429 - acc: 0.7710 - val_loss: 0.8762 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.70150 to 0.70650, saving model to check_samul_resnet.ckpt\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.6318 - acc: 0.7765 - val_loss: 0.8581 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.70650\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.6297 - acc: 0.7786 - val_loss: 0.9849 - val_acc: 0.6764\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.70650\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.6305 - acc: 0.7762 - val_loss: 0.8385 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.70650 to 0.71230, saving model to check_samul_resnet.ckpt\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 50s 317ms/step - loss: 0.6239 - acc: 0.7786 - val_loss: 1.0436 - val_acc: 0.6479\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.71230\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.6112 - acc: 0.7832 - val_loss: 1.2462 - val_acc: 0.6286\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.71230\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.6130 - acc: 0.7818 - val_loss: 0.9210 - val_acc: 0.6886\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.71230\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 0.6068 - acc: 0.7868 - val_loss: 0.7885 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.71230 to 0.72220, saving model to check_samul_resnet.ckpt\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.6010 - acc: 0.7888 - val_loss: 0.8297 - val_acc: 0.7214\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.72220\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 46s 295ms/step - loss: 0.5913 - acc: 0.7929 - val_loss: 0.8550 - val_acc: 0.7141\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.72220\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 47s 296ms/step - loss: 0.5835 - acc: 0.7948 - val_loss: 0.9136 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.72220\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 0.5829 - acc: 0.7937 - val_loss: 0.9331 - val_acc: 0.6891\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.72220\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.5759 - acc: 0.7962 - val_loss: 1.1279 - val_acc: 0.6426\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.72220\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 48s 302ms/step - loss: 0.5791 - acc: 0.7946 - val_loss: 1.0193 - val_acc: 0.6822\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.72220\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.5716 - acc: 0.7970 - val_loss: 0.8728 - val_acc: 0.7121\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.72220\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.5636 - acc: 0.8022 - val_loss: 0.7743 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.72220 to 0.73240, saving model to check_samul_resnet.ckpt\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 46s 294ms/step - loss: 0.5568 - acc: 0.8031 - val_loss: 0.8671 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.73240\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 46s 289ms/step - loss: 0.5508 - acc: 0.8047 - val_loss: 0.8944 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.73240\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 46s 295ms/step - loss: 0.5520 - acc: 0.8055 - val_loss: 0.9156 - val_acc: 0.7012\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.73240\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 0.5457 - acc: 0.8062 - val_loss: 0.9456 - val_acc: 0.6946\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.73240\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 0.5439 - acc: 0.8060 - val_loss: 0.8367 - val_acc: 0.7291\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.73240\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 46s 291ms/step - loss: 0.5309 - acc: 0.8099 - val_loss: 0.8312 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.73240\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 46s 290ms/step - loss: 0.5393 - acc: 0.8094 - val_loss: 0.9757 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.73240\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 46s 290ms/step - loss: 0.5237 - acc: 0.8136 - val_loss: 0.8794 - val_acc: 0.7140\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.73240\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 46s 291ms/step - loss: 0.5222 - acc: 0.8160 - val_loss: 0.7762 - val_acc: 0.7427\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.73240 to 0.74270, saving model to check_samul_resnet.ckpt\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.5137 - acc: 0.8177 - val_loss: 0.8804 - val_acc: 0.7144\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.74270\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 46s 295ms/step - loss: 0.5123 - acc: 0.8180 - val_loss: 0.9223 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.74270\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 47s 298ms/step - loss: 0.5061 - acc: 0.8213 - val_loss: 0.9253 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.74270\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 48s 302ms/step - loss: 0.4976 - acc: 0.8242 - val_loss: 0.7807 - val_acc: 0.7419\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.74270\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 48s 304ms/step - loss: 0.5025 - acc: 0.8225 - val_loss: 0.9543 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.74270\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 51s 323ms/step - loss: 0.4957 - acc: 0.8245 - val_loss: 0.8558 - val_acc: 0.7333\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.74270\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.4998 - acc: 0.8216 - val_loss: 0.8400 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.74270\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 0.4906 - acc: 0.8256 - val_loss: 0.8755 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.74270\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 48s 302ms/step - loss: 0.4836 - acc: 0.8280 - val_loss: 0.8356 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.74270\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 48s 303ms/step - loss: 0.4743 - acc: 0.8339 - val_loss: 1.0549 - val_acc: 0.6704\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.74270\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 50s 319ms/step - loss: 0.4821 - acc: 0.8288 - val_loss: 0.8193 - val_acc: 0.7384\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.74270\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 48s 306ms/step - loss: 0.4689 - acc: 0.8324 - val_loss: 0.8858 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.74270\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 55s 351ms/step - loss: 0.4663 - acc: 0.8341 - val_loss: 0.9300 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.74270\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 53s 338ms/step - loss: 0.4706 - acc: 0.8341 - val_loss: 0.8075 - val_acc: 0.7398\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.74270\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 0.4609 - acc: 0.8365 - val_loss: 0.9912 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.74270\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 53s 334ms/step - loss: 0.4568 - acc: 0.8369 - val_loss: 0.8202 - val_acc: 0.7382\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.74270\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 48s 304ms/step - loss: 0.4572 - acc: 0.8377 - val_loss: 0.8479 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.74270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f8db2fd30>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path_resnet = \"check_samul_resnet.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path_resnet, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1)\n",
    "\n",
    "resnet50.fit(train_generator, \n",
    "          validation_data=(validation_generator),\n",
    "          epochs=100,\n",
    "          callbacks=[checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2f08bec-fc9c-4a4f-848a-c7558130b42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 10s 244ms/step - loss: 0.7560 - acc: 0.7478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7559830546379089, 0.7477999925613403]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.load_weights(checkpoint_path_resnet)\n",
    "\n",
    "resnet50.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8b8df783-8128-4fae-af01-52e0e05ed34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'data/2차/samul_data/test'\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb835b5-48ac-4411-9ffe-4f35e0d93e19",
   "metadata": {},
   "source": [
    "# test 데이터를 불러옴 (test data는 하위 디렉토리가 존재 하지 않고 이미지만 존재하므로 classes=[','] 을 이용하여 이미지만 불러옴\n",
    "## 여기서 ['.']안의 값으로 데이터를 인식하기 때문에 하위 디렉토리가 따로 인식되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0f68a559-ad1b-40d0-a032-0a2f3341decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "    # only read images from `test` directory\n",
    "    classes=['.'],\n",
    "    # don't generate labels\n",
    "    class_mode=None,\n",
    "    # don't shuffle\n",
    "    shuffle=False,\n",
    "    # use same size as in training\n",
    "    target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "42cb44ea-9b9f-42d1-b2ed-d8802df41a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moons\\anaconda3\\envs\\dacon_re\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2030: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "preds = resnet50.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "347d0f34-4917-4141-aa8e-406d28e554ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652f5c1-1eb7-4276-a153-5293c91cd61f",
   "metadata": {},
   "source": [
    "# 제출 할 수 있는 형태로 DataFrame 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a3adf4e-9c9a-4dce-a284-b78a9cbb6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5201421c-a16a-41b9-822c-b9fc54b862f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv('data/2차/samul_data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "451754ca-4f11-4098-9c5c-9e5153924367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id target\n",
       "0  0000.jpg  human\n",
       "1  0001.jpg  human\n",
       "2  0002.jpg  human\n",
       "3  0003.jpg  human\n",
       "4  0004.jpg  human"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436aecc6-5e3d-4689-9da6-feac6719fb37",
   "metadata": {},
   "source": [
    "# argmax -> 값이 최대인 index값을 뱉어냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fabc1bdc-9b67-4daf-a01e-0aa2d79cca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_real=preds.argmax(axis=-1)\n",
    "#onehot 으로 나온 predict 값을 class 숫자 값으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9d723cbb-f254-4e0a-b67c-bd885cb19c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 0, ..., 4, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c0c4b2e0-6e08-45bf-9128-0d69ba333af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (train_generator.class_indices)\n",
    "#label 이름 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f74663fe-9e75-4765-a339-31159556ec95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d4c5aa5c-6241-46c0-af58-791a4438ce22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#추출된 label 이름과 class 숫자 값을 매핑 하기\n",
    "class_list = []\n",
    "\n",
    "for i in range(0,len(class_real)):\n",
    "    for j in label_map.keys():\n",
    "\n",
    "        if (class_real[i] == label_map[j]) :\n",
    "            class_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0480ec9c-728d-4a58-bea5-085609a66132",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['target']=pd.DataFrame(class_list,columns = ['target'] ).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0c05357f-ab2d-403f-8230-3cda1bedda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('samul_first_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25965ab-6b36-4a8d-a105-7fec2b543e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
